{"cells":[{"cell_type":"markdown","metadata":{"id":"8NFZ99Ar-cmI"},"source":["# Import Libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23999,"status":"ok","timestamp":1689836586381,"user":{"displayName":"DongKyu Moon","userId":"13679376230758781592"},"user_tz":-540},"id":"PUwrN45r-j6Q","outputId":"7aa141dc-344e-49c7-fa6a-c13f9c3debb5"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gP7rCOZl-cmJ"},"outputs":[],"source":["import os\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import warnings\n","warnings.filterwarnings('ignore')\n","import random\n","random.seed(530)\n","\n","from glob import glob\n","from tqdm.auto import tqdm\n","\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error, r2_score\n","\n","import tensorflow as tf\n","from keras.layers import Lambda, Input, concatenate, Conv1D, MaxPooling1D, Dense, Embedding, Flatten\n","from keras import backend as K\n","from keras.callbacks import ModelCheckpoint, EarlyStopping"]},{"cell_type":"markdown","metadata":{"id":"b7M4Ldnt-cmJ"},"source":["# Data Prepare"]},{"cell_type":"markdown","metadata":{"id":"DiFixLmh-cmK"},"source":["## Data Load"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C7A0uoHd-cmK"},"outputs":[],"source":["data_path = \"/content/drive/MyDrive/DKU/Ubiosis/total_data.csv\"\n","data_df = pd.read_csv(data_path)"]},{"cell_type":"markdown","metadata":{"id":"MAiM7Bk8Imoq"},"source":["## Data Pre-Processing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"szWTqgxLIpwa"},"outputs":[],"source":["def prepare_dataset(data_df, c_mode = \"all\", r_mode=\"org\", scale_list = [1,1,1,1,1,1,1,1,1]):\n","    # 결측치 제거\n","    data_df.dropna(axis=0,inplace=True)\n","\n","    # 데이터 정보 별 데이터프레임 분할\n","    radius_df = data_df.iloc[:,:1]\n","    cis1_df = data_df.iloc[:,1:6001]\n","    cis2_df = data_df.iloc[:,6001:12001]\n","    shear_df = data_df.iloc[:,12001:]\n","    shear_df = shear_df.div(scale_list, axis=1)\n","    re_cols = [\"1\",\"2\",\"5\",\"10\",\"50\",\"100\",\"150\",\"300\",\"1000\"]\n","    re_shear_df = shear_df[re_cols]\n","\n","    if r_mode == \"org\":\n","        if c_mode == \"all\":\n","            data = pd.concat([radius_df, cis1_df, cis2_df,re_shear_df],axis=1)\n","        elif c_mode == \"only2\":\n","            data = pd.concat([radius_df, cis2_df,re_shear_df],axis=1)\n","        else:\n","            data = pd.DataFrame()\n","\n","    elif r_mode == \"ohe\":\n","        # one-hot encoding\n","        ohe_cols = []\n","        for i in range(0,19):\n","            ohe_cols.append(((310+i)/100))\n","\n","        ohe_target = np.array(ohe_cols).reshape(-1,1)\n","        ohe_value = np.array(radius_df[\"RADIUS\"]).reshape(-1,1)\n","\n","        ohe = OneHotEncoder()\n","        ohe.fit(ohe_target)\n","\n","        ohe_labels = ohe.transform(ohe_value)\n","        ohe_targets = ohe_labels.toarray()\n","\n","        ohe_df = pd.DataFrame(columns=ohe_cols,data=ohe_targets)\n","\n","        if c_mode == \"all\":\n","            data = pd.concat([ohe_df, cis1_df, cis2_df,re_shear_df],axis=1)\n","        elif c_mode == \"only2\":\n","            data = pd.concat([ohe_df, cis2_df,re_shear_df],axis=1)\n","        else:\n","            data = pd.DataFrame()\n","    else:\n","        data = pd.DataFrame()\n","\n","    return data\n","\n","c_mode = \"all\" # all / only2\n","r_mode = \"org\" # org / ohe\n","scale_list = [10,10,10,10,10,10,10,15,20]\n","\n","data = prepare_dataset(data_df, c_mode, r_mode, scale_list)"]},{"cell_type":"markdown","metadata":{"id":"xgnmF66M-cmL"},"source":["# Dataset Split"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5-38nd_w-cmL"},"outputs":[],"source":["train, test = train_test_split(data, test_size=0.2, random_state=530)\n","\n","tr_radius = np.array(train.iloc[:,:-12009].values)\n","tr_cis1 = np.array(train.iloc[:,-12009:-6009].values)\n","tr_cis2 = np.array(train.iloc[:,-6009:-9].values)\n","tr_shear = np.array(train.iloc[:,-9:-8].values)\n","\n","te_radius = np.array(test.iloc[:,:-12009].values)\n","te_cis1 = np.array(test.iloc[:,-12009:-6009].values)\n","te_cis2 = np.array(test.iloc[:,-6009:-9].values)\n","te_shear = np.array(test.iloc[:,-9:-8].values)"]},{"cell_type":"markdown","metadata":{"id":"ZZqr6W3P-cmL"},"source":["# Model Define"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dgR1ffQZ-cmL"},"outputs":[],"source":["def get_model(m_mode, input_dim_X1, input_dim_X2, input_dim_X3, output_dim):\n","    # 각 입력에 대한 입력 레이어 생성\n","    input_X1 = Input(shape=(input_dim_X1,)) # cis 1\n","    input_X2 = Input(shape=(input_dim_X2,)) # cis 2\n","    input_X3 = Input(shape=(input_dim_X3,)) # extra\n","\n","    if m_mode == \"org\":\n","        X1_merged = concatenate([input_X3, input_X1])\n","        X2_merged = concatenate([input_X3, input_X2])\n","    elif m_mode == \"emb\":\n","\n","        # 임베딩 레이어 적용\n","        embedded = Embedding(input_dim=10000, output_dim=128, input_length=input_dim_X3)(input_X3)\n","        embedded = Flatten()(embedded)\n","        X1_merged = concatenate([embedded, input_X1])\n","        X2_merged = concatenate([embedded, input_X2])\n","\n","    X1_reshaped = Lambda(lambda x: K.expand_dims(x, axis=-1))(X1_merged)\n","    X2_reshaped = Lambda(lambda x: K.expand_dims(x, axis=-1))(X2_merged)\n","\n","    # cis 1\n","    x1 = Conv1D(512, 3, activation='relu', strides=2, padding=\"same\")(X1_reshaped)\n","    x1 = MaxPooling1D(2)(x1)\n","    x1 = Conv1D(256, 3, activation='relu', strides=2, padding=\"same\")(x1)\n","    x1 = MaxPooling1D(2)(x1)\n","    x1 = Conv1D(128, 3, activation='relu', strides=2, padding=\"same\")(x1)\n","    x1 = MaxPooling1D(2)(x1)\n","    x1 = Conv1D(64, 3, activation='relu', strides=2, padding=\"same\")(x1)\n","    x1 = MaxPooling1D(2)(x1)\n","    x1 = Conv1D(32, 3, activation='relu', strides=2, padding=\"same\")(x1)\n","    x1 = MaxPooling1D(2)(x1)\n","    x1 = Conv1D(16, 3, activation='relu', strides=2, padding=\"same\")(x1)\n","    x1 = MaxPooling1D(2)(x1)\n","    x1 = Flatten()(x1)\n","\n","    # cis 2\n","    x2 = Conv1D(512, 3, activation='relu', strides=2, padding=\"same\")(X2_reshaped)\n","    x2 = MaxPooling1D(2)(x2)\n","    x2 = Conv1D(256, 3, activation='relu', strides=2, padding=\"same\")(x2)\n","    x2 = MaxPooling1D(2)(x2)\n","    x2 = Conv1D(128, 3, activation='relu', strides=2, padding=\"same\")(x2)\n","    x2 = MaxPooling1D(2)(x2)\n","    x2 = Conv1D(64, 3, activation='relu', strides=2, padding=\"same\")(x2)\n","    x2 = MaxPooling1D(2)(x2)\n","    x2 = Conv1D(32, 3, activation='relu', strides=2, padding=\"same\")(x2)\n","    x2 = MaxPooling1D(2)(x2)\n","    x2 = Conv1D(16, 3, activation='relu', strides=2, padding=\"same\")(x2)\n","    x2 = MaxPooling1D(2)(x2)\n","    x2 = Flatten()(x2)\n","\n","    # 모델 통합\n","    x = concatenate([x1, x2])\n","    output = Dense(output_dim)(x)\n","\n","    model = tf.keras.models.Model(inputs=[input_X1, input_X2, input_X3], outputs=output)\n","\n","    # 모델 컴파일\n","    opt = tf.keras.optimizers.legacy.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=True)\n","    model.compile(optimizer=opt, loss='mae',\n","                  metrics=[tf.keras.metrics.MeanSquaredError(),tf.keras.metrics.RootMeanSquaredError(),\n","                           tf.keras.metrics.MeanAbsoluteError(),tf.keras.metrics.MeanAbsolutePercentageError()])\n","\n","    return model"]},{"cell_type":"markdown","metadata":{"id":"WoslloY7-cmL"},"source":["# Model Train"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kwcovU3g-cmL"},"outputs":[],"source":["m_mode = \"emb\"\n","if r_mode ==\"ohe\":\n","    m_mode = \"org\"\n","input_dim_X1, input_dim_X2, input_dim_X3, output_dim = tr_cis1.shape[1], tr_cis2.shape[1], tr_radius.shape[1], tr_shear.shape[1]\n","\n","model = get_model(m_mode, input_dim_X1, input_dim_X2, input_dim_X3, output_dim)"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"code","colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"Hq-YMuVg-cmL"},"outputs":[],"source":["# 모델 학습\n","es = EarlyStopping(monitor='val_loss', patience=20, mode='min')\n","history = model.fit([tr_cis1, tr_cis2, tr_radius], tr_shear, epochs=100, batch_size=64,\n","                    validation_split=0.2, validation_batch_size=64,\n","                    verbose=1, callbacks=es)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NhYjlmTjJBSJ"},"outputs":[],"source":["# Visualize Train History\n","def vis(history,name) :\n","    plt.title(f\"{name.upper()}\")\n","    plt.xlabel('epochs')\n","    plt.ylabel(f\"{name.lower()}\")\n","    value = history.history.get(name)\n","    val_value = history.history.get(f\"val_{name}\",None)\n","    epochs = range(1, len(value)+1)\n","    plt.plot(epochs, value, 'b-', label=f'training {name}')\n","    if val_value is not None :\n","        plt.plot(epochs, val_value, 'r:', label=f'validation {name}')\n","    plt.legend(loc='upper center', bbox_to_anchor=(0.05, 1.2) , fontsize=10 , ncol=1)\n","\n","def plot_history(history) :\n","    key_value = list(set([i.split(\"val_\")[-1] for i in list(history.history.keys())]))\n","    plt.figure(figsize=(12, 4))\n","    for idx , key in enumerate(key_value) :\n","        plt.subplot(1, len(key_value), idx+1)\n","        vis(history, key)\n","    plt.tight_layout()\n","    plt.show()\n","\n","plot_history(history)"]},{"cell_type":"markdown","metadata":{"id":"RJ82u0ki-cmL"},"source":["# Model Test"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2172,"status":"ok","timestamp":1688313307728,"user":{"displayName":"DongKyu Moon","userId":"13679376230758781592"},"user_tz":-540},"id":"CIoIFaKA-cmL","outputId":"95bee881-79ed-4579-e940-0ae99396a355"},"outputs":[],"source":["y_pred = model.predict([te_cis1, te_cis2, te_radius])\n","print(f\"Predict Result\\n{y_pred[:5]}\\n\")\n","print(f\"Test Dataset\\n{te_shear[:5]}\")"]},{"cell_type":"markdown","metadata":{"id":"KIxOMmGV-cmM"},"source":["# Evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"imGOjreJ-cmM"},"outputs":[],"source":["scale_list.sort(reverse=True)\n","def unscale_values(y_list):\n","    unscale_list = [x * y for x,y in zip(y_list,scale_list)]\n","    return unscale_list\n","\n","un_y_pred = unscale_values(y_pred)\n","un_y_test = unscale_values(te_shear)\n","\n","col_list = [\"1000\",\"300\", \"150\", \"100\", \"50\", \"10\", \"5\", \"2\", \"1\"]\n","y_real_df = pd.DataFrame(columns=col_list, data=un_y_test)\n","y_pred_df = pd.DataFrame(columns=col_list, data=un_y_pred)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"swSXhZ0Z-cmM"},"outputs":[],"source":["def pearson_correlation_coefficient(X, Y):\n","    \"\"\"\n","    두 변수 X와 Y 간의 피어슨 상관계수를 계산하는 함수\n","\n","    :param X: 첫 번째 변수의 값들을 담은 1차원 NumPy 배열\n","    :param Y: 두 번째 변수의 값들을 담은 1차원 NumPy 배열\n","    :return: 피어슨 상관계수\n","    \"\"\"\n","    # 변수들의 평균 계산\n","    mean_X = np.mean(X)\n","    mean_Y = np.mean(Y)\n","\n","    # 각 변수들의 편차 계산\n","    deviation_X = X - mean_X\n","    deviation_Y = Y - mean_Y\n","\n","    # 피어슨 상관계수의 분자 계산\n","    numerator = np.sum(deviation_X * deviation_Y)\n","\n","    # 피어슨 상관계수의 분모 계산\n","    denominator = np.sqrt(np.sum(deviation_X ** 2) * np.sum(deviation_Y ** 2))\n","\n","    # 피어슨 상관계수 계산\n","    pearson_coefficient = numerator / denominator\n","\n","    return pearson_coefficient"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RAZCzXUq-cmM"},"outputs":[],"source":["mae_list = []\n","mse_list = []\n","rmse_list = []\n","mape_list = []\n","r2_list = []\n","pc_list = []\n","for i in range(len(col_list)):\n","    #print(f\"{col_list[i]}\")\n","    real_v = list(y_real_df[col_list[i]].values)\n","    pred_v = list(y_pred_df[col_list[i]].values)\n","\n","    mae = mean_absolute_error(real_v, pred_v)\n","    mse = mean_squared_error(real_v, pred_v)\n","    rmse = np.sqrt(mse)\n","    mape = mean_absolute_percentage_error(real_v, pred_v)\n","    r2_scores = r2_score(real_v, pred_v)\n","    pearson_scores = pearson_correlation_coefficient(real_v, pred_v)\n","\n","    mae_list.append(mae)\n","    mse_list.append(mse)\n","    rmse_list.append(rmse)\n","    mape_list.append(mape)\n","    r2_list.append(r2_scores)\n","    pc_list.append(pearson_scores)\n","\n","ev_df = pd.DataFrame(columns=[\"MAE\",\"MSE\",\"RMSE\",\"MAPE\",\"R2\",\"Pearson\"])\n","ev_df[\"MAE\"] = mae_list\n","ev_df[\"MSE\"] = mse_list\n","ev_df[\"RMSE\"] = rmse_list\n","ev_df[\"MAPE\"] = mape_list\n","ev_df[\"R2\"] = r2_list\n","ev_df[\"Pearson\"] = pc_list\n","ev_df.index = col_list"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zH2Xx78u-cmM"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S77RwHYv-cmM"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jgjZAien-cmM"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat":4,"nbformat_minor":0}
